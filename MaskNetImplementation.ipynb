{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1650194173266,
     "user": {
      "displayName": "2K19/SE/076 MRIGANK SONDHI",
      "userId": "07895027365543689127"
     },
     "user_tz": -330
    },
    "id": "lQmaWqOGlXx1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOG6gouEN6n9"
   },
   "source": [
    "# Loading the pre-trained FaceNet and MaskNet Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "executionInfo": {
     "elapsed": 530,
     "status": "error",
     "timestamp": 1650194543648,
     "user": {
      "displayName": "2K19/SE/076 MRIGANK SONDHI",
      "userId": "07895027365543689127"
     },
     "user_tz": -330
    },
    "id": "9mutHwzZmIjU",
    "outputId": "f73b8692-0c30-44b6-f64a-356dfb7db55b"
   },
   "outputs": [],
   "source": [
    "path1 = r'FaceNetSavedModel\\1.prototxt'\n",
    "path2 = r'FaceNetSavedModel\\2.caffemodel'\n",
    "FaceNet = cv2.dnn.readNet(path1, path2)\n",
    "MaskNet = load_model('MaskNetSavedModel\\MaskNet.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function responsible for detecting faces and predicting whether mask is worn or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectFacePredictMask(frame, FaceNet, MaskNet):\n",
    "    (height, width) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224), (104.0, 177.0, 123.0))\n",
    "\n",
    "    FaceNet.setInput(blob)\n",
    "    detections = FaceNet.forward()\n",
    "    #print(detections.shape)\n",
    "\n",
    "    faces = []\n",
    "    locations = []\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (X_start, Y_start, X_end, Y_end) = box.astype('int')\n",
    "\n",
    "            (X_start, Y_start) = (max(0, X_start), max(0, Y_start))\n",
    "            (X_end, Y_end) = (min(width - 1, X_end), min(height - 1, Y_end))\n",
    "\n",
    "            face = frame[Y_start:Y_end, X_start:X_end]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            face = img_to_array(face)\n",
    "            face = preprocess_input(face)\n",
    "\n",
    "            faces.append(face)\n",
    "            locations.append((X_start, Y_start, X_end, Y_end))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        faces = np.array(faces, dtype='float32')\n",
    "        predictions = MaskNet.predict(faces, batch_size=32)\n",
    "\n",
    "    return (locations, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function which detects faces, predicts mask is worn or not and outputs the result to the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zQJAgBsmIei"
   },
   "outputs": [],
   "source": [
    "video_stream = VideoStream(src=0).start()\n",
    "\n",
    "while True:\n",
    "    frame = video_stream.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    (locations, predictions) = DetectFacePredictMask(frame, FaceNet, MaskNet)\n",
    "\n",
    "    for (box, pred) in zip(locations, predictions):\n",
    "        (X_start, Y_start, X_end, Y_end) = box\n",
    "        \n",
    "        label = 'Mask' if (pred >= 0.5) else 'No Mask'\n",
    "        color = (0, 255, 0) if (label == 'Mask') else (0, 0, 255)\n",
    "\n",
    "        if (label == 'Mask'):\n",
    "            label = f\"{label}: {'%.2f' %(pred*100)}%\"  \n",
    "        else:\n",
    "            label = f\"{label}: {'%.2f' %((1-pred)*100)}%\"\n",
    "\n",
    "        cv2.putText(frame, label, (X_start - 55, Y_start - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        cv2.rectangle(frame, (X_start, Y_start), (X_end, Y_end), color, 2)\n",
    "\n",
    "    cv2.namedWindow('MaskNet', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('MaskNet', 800, 600)\n",
    "    cv2.imshow('MaskNet', frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    #quit using 'Q'\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video_stream.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPTYuOk5xDmJ/wravRIJvh9",
   "collapsed_sections": [],
   "name": "FaceNetModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
